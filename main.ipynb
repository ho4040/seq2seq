{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "\n",
    "* Simple Seq2seq model with LSTM\n",
    "* Hyper parameter optimization with GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, LSTM, TimeDistributed, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build simple seq2seq dataset\n",
    "\n",
    "* without teacher forcing\n",
    "* with teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for k in range(10000):\n",
    "  x = np.linspace(0, 30, 200)\n",
    "  y = np.zeros(shape=(200,))\n",
    "\n",
    "  for i in range(3):\n",
    "    fq = np.random.random() * 4 + 1e-8\n",
    "    start_theta = np.random.random() * 3.14 * 2\n",
    "    height = np.random.random() * 0.5 + 0.5\n",
    "    y = y + np.sin(start_theta + x*fq)*height\n",
    "  y = y / (np.max(y)-np.min(y))\n",
    "  x_list.append(y[:100])\n",
    "  y_list.append(y[100:])\n",
    "\n",
    "x_train = np.array(x_list[:9000]).reshape([-1, 100, 1])\n",
    "y_train = np.array(y_list[:9000]).reshape([-1, 100, 1])\n",
    "x_test = np.array(x_list[9000:]).reshape([-1, 100, 1])\n",
    "y_test = np.array(y_list[9000:]).reshape([-1, 100, 1])\n",
    "\n",
    "\n",
    "# with teacher forcing\n",
    "decoder_train_input_data = np.concatenate([x_train[:, -2:-1, :], y_train[:, :-1, :]], axis=1)\n",
    "decoder_test_input_data = np.concatenate([x_test[:, -2:-1, :], y_test[:, :-1, :]], axis=1)\n",
    "\n",
    "# without teacher forcing\n",
    "# decoder_train_input_data = np.ones(shape=x_train.shape)\n",
    "# decoder_test_input_data = np.ones(shape=x_test.shape)\n",
    "\n",
    "print(\"train_data\", x_train.shape, y_train.shape)\n",
    "print(\"test_data\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "dim_lstm_state_size = Integer(low=10, high=1024, name='lstm_state_size')\n",
    "dim_lstm_depth  = Integer(low=1, high=3, name='lstm_depth')\n",
    "dimensions = [dim_learning_rate, dim_lstm_state_size, dim_lstm_depth]\n",
    "default_parameters = [1e-5, 10, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define create model function\n",
    "\n",
    "create nn model from params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, lstm_state_size, lstm_depth=1):\n",
    "  K.reset_uids()\n",
    "  K.clear_session()  \n",
    "\n",
    "  encoder_input = Input(shape=[100, 1])\n",
    "  x = encoder_input\n",
    "\n",
    "  for j in range(lstm_depth):\n",
    "    if j < lstm_depth-1:\n",
    "      x = LSTM(lstm_state_size, return_sequences=True)(x)\n",
    "    else:\n",
    "      x, encoder_state1, encoder_state2 = LSTM(lstm_state_size, return_state=True)(x)\n",
    "  \n",
    "  encoder_state = [encoder_state1, encoder_state2]\n",
    "  decoder_input = Input(shape=[None, 1])\n",
    "  x = decoder_input\n",
    "\n",
    "  for j in range(lstm_depth):\n",
    "    if j == 0:\n",
    "      x = LSTM(lstm_state_size, return_sequences=True)(x, initial_state=encoder_state)\n",
    "    else:\n",
    "      x = LSTM(lstm_state_size, return_sequences=True)(x)\n",
    "\n",
    "  output = TimeDistributed(Dense(1, activation=\"tanh\"))(x)\n",
    "\n",
    "  model = Model([encoder_input, decoder_input], output)\n",
    "  optimizer = Adam(lr=learning_rate)\n",
    "  model.compile(optimizer=optimizer, loss='mse', metrics=['mae']) \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fitness function\n",
    "\n",
    "model performance check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mae = 1e+1000\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, lstm_state_size, lstm_depth):\n",
    "  print(\"learning rate : %f\"%learning_rate)\n",
    "  print(\"lstm_state_size : %d\"%lstm_state_size)\n",
    "  print(\"lstm_depth : %d\"%lstm_depth)\n",
    "\n",
    "  model = create_model(learning_rate, lstm_state_size, lstm_depth)\n",
    "  validation_data = [[x_test, decoder_test_input_data], y_test]\n",
    "  history = model.fit([x_train, decoder_train_input_data], y_train, epochs=3, validation_data=validation_data)  \n",
    "  val_mae = history.history['val_mean_absolute_error'][-1]\n",
    "\n",
    "  global best_mae\n",
    "\n",
    "  if val_mae < best_mae:\n",
    "    model.save(\"./best_model.h5\")\n",
    "    best_mae = val_mae\n",
    "    del model\n",
    "\n",
    "  return val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter serach with GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=40,\n",
    "                            x0=default_parameters)"
   ]
  }
 ]
}